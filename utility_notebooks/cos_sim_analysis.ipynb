{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cos_similarities(width_power):\n",
    "    \"\"\"\n",
    "    Analyze cosine similarities between before and after SAE weights for a given width.\n",
    "    \n",
    "    Args:\n",
    "        width_power (int): Power of 2 for width (e.g., 14 for 2^14 or 16 for 2^16)\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    from huggingface_hub import hf_hub_download\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    trainer_ids = list(range(6))\n",
    "    before_local_dir = \"before_cos_sim_saes\"\n",
    "    after_local_dir = \"after_cos_sim_saes\"\n",
    "\n",
    "\n",
    "    width_str = f\"2pow{width_power}\"\n",
    "\n",
    "    before_repo_id = f\"canrager/saebench_gemma-2-2b_width-{width_str}_date-0107\"\n",
    "    after_repo_id = \"adamkarvonen/new_kl_finetunes\"\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for trainer_id in trainer_ids:\n",
    "        base_path = f\"gemma-2-2b_top_k_width-{width_str}_date-0107/resid_post_layer_12/trainer_{trainer_id}/ae.pt\"\n",
    "        \n",
    "        path_to_before_params = hf_hub_download(\n",
    "            repo_id=before_repo_id,\n",
    "            filename=base_path,\n",
    "            force_download=False,\n",
    "            local_dir=before_local_dir,\n",
    "        )\n",
    "\n",
    "        path_to_after_params = hf_hub_download(\n",
    "            repo_id=after_repo_id,\n",
    "            filename=base_path,\n",
    "            force_download=False,\n",
    "            local_dir=after_local_dir,\n",
    "        )\n",
    "\n",
    "        before_params = torch.load(path_to_before_params)\n",
    "        after_params = torch.load(path_to_after_params)\n",
    "\n",
    "        # ... existing code for calculating decoder similarities ...\n",
    "        before_decoder = before_params['decoder.weight']\n",
    "        after_decoder = after_params['decoder.weight']\n",
    "\n",
    "        before_decoder_norm = before_decoder / before_decoder.norm(dim=0, keepdim=True)\n",
    "        after_decoder_norm = after_decoder / after_decoder.norm(dim=0, keepdim=True)\n",
    "        \n",
    "        decoder_cos_sims = torch.sum(before_decoder_norm * after_decoder_norm, dim=0)\n",
    "        \n",
    "        # Calculate decoder statistics\n",
    "        decoder_stats = {\n",
    "            'mean': decoder_cos_sims.mean().item(),\n",
    "            'median': decoder_cos_sims.median().item(),\n",
    "            'std': decoder_cos_sims.std().item(),\n",
    "            'min': decoder_cos_sims.min().item(),\n",
    "            'max': decoder_cos_sims.max().item(),\n",
    "            'p25': decoder_cos_sims.quantile(0.25).item(),\n",
    "            'p75': decoder_cos_sims.quantile(0.75).item(),\n",
    "        }\n",
    "        \n",
    "        # ... existing code for calculating encoder similarities ...\n",
    "        before_encoder = before_params['encoder.weight']\n",
    "        after_encoder = after_params['encoder.weight']\n",
    "\n",
    "        before_encoder_norm = before_encoder / before_encoder.norm(dim=1, keepdim=True)\n",
    "        after_encoder_norm = after_encoder / after_encoder.norm(dim=1, keepdim=True)\n",
    "\n",
    "        decoder_norm_ratios = after_decoder.norm(dim=0) / before_decoder.norm(dim=0)\n",
    "        print(f\"\\nTrainer {trainer_id} Norm Ratios:\")\n",
    "        print(f\"Decoder (after/before):\")\n",
    "        print(f\"  Mean: {decoder_norm_ratios.mean():.4f}\")\n",
    "        print(f\"  Median: {decoder_norm_ratios.median():.4f}\")\n",
    "        print(f\"  Min/Max: {decoder_norm_ratios.min():.4f}/{decoder_norm_ratios.max():.4f}\")\n",
    "        print(f\"  25th/75th percentile: {decoder_norm_ratios.quantile(0.25):.4f}/{decoder_norm_ratios.quantile(0.75):.4f}\")\n",
    "        \n",
    "\n",
    "        # Print encoder norm ratios\n",
    "        encoder_norm_ratios = after_encoder.norm(dim=1) / before_encoder.norm(dim=1)\n",
    "        print(f\"Encoder (after/before):\")\n",
    "        print(f\"  Mean: {encoder_norm_ratios.mean():.4f}\")\n",
    "        print(f\"  Median: {encoder_norm_ratios.median():.4f}\")\n",
    "        print(f\"  Min/Max: {encoder_norm_ratios.min():.4f}/{encoder_norm_ratios.max():.4f}\")\n",
    "        print(f\"  25th/75th percentile: {encoder_norm_ratios.quantile(0.25):.4f}/{encoder_norm_ratios.quantile(0.75):.4f}\\n\")\n",
    "\n",
    "        encoder_cos_sims = torch.sum(before_encoder_norm * after_encoder_norm, dim=1)\n",
    "\n",
    "\n",
    "        assert (encoder_cos_sims.shape[0] == 16384) or (encoder_cos_sims.shape[0] == 65536)\n",
    "        assert (decoder_cos_sims.shape[0] == 16384) or (decoder_cos_sims.shape[0] == 65536)\n",
    "        \n",
    "        encoder_stats = {\n",
    "            'mean': encoder_cos_sims.mean().item(),\n",
    "            'median': encoder_cos_sims.median().item(),\n",
    "            'std': encoder_cos_sims.std().item(),\n",
    "            'min': encoder_cos_sims.min().item(),\n",
    "            'max': encoder_cos_sims.max().item(),\n",
    "            'p25': encoder_cos_sims.quantile(0.25).item(),\n",
    "            'p75': encoder_cos_sims.quantile(0.75).item(),\n",
    "        }\n",
    "        \n",
    "        result = {\n",
    "            'trainer_id': trainer_id,\n",
    "            'decoder': decoder_stats,\n",
    "            'encoder': encoder_stats,\n",
    "            'decoder_cos_sims': decoder_cos_sims.cpu().numpy(),\n",
    "            'encoder_cos_sims': encoder_cos_sims.cpu().numpy(),\n",
    "        }\n",
    "        all_results.append(result)\n",
    "        \n",
    "        print(f\"\\nTrainer {trainer_id}:\")\n",
    "        print(f\"Decoder statistics:\")\n",
    "        print(f\"  Mean: {decoder_stats['mean']:.4f}\")\n",
    "        print(f\"  Median: {decoder_stats['median']:.4f}\")\n",
    "        print(f\"  Std: {decoder_stats['std']:.4f}\")\n",
    "        print(f\"  Min/Max: {decoder_stats['min']:.4f}/{decoder_stats['max']:.4f}\")\n",
    "        print(f\"  25th/75th percentile: {decoder_stats['p25']:.4f}/{decoder_stats['p75']:.4f}\")\n",
    "        \n",
    "        print(f\"\\nEncoder statistics:\")\n",
    "        print(f\"  Mean: {encoder_stats['mean']:.4f}\")\n",
    "        print(f\"  Median: {encoder_stats['median']:.4f}\")\n",
    "        print(f\"  Std: {encoder_stats['std']:.4f}\")\n",
    "        print(f\"  Min/Max: {encoder_stats['min']:.4f}/{encoder_stats['max']:.4f}\")\n",
    "        print(f\"  25th/75th percentile: {encoder_stats['p25']:.4f}/{encoder_stats['p75']:.4f}\")\n",
    "\n",
    "    # Plot creation\n",
    "    k_values = [20, 40, 80, 160, 320, 640]\n",
    "    decoder_p25 = [result['decoder']['p25'] for result in all_results]\n",
    "    decoder_p75 = [result['decoder']['p75'] for result in all_results]\n",
    "    encoder_p25 = [result['encoder']['p25'] for result in all_results]\n",
    "    encoder_p75 = [result['encoder']['p75'] for result in all_results]\n",
    "\n",
    "    decoder_range = np.array(decoder_p75) - np.array(decoder_p25)\n",
    "    encoder_range = np.array(encoder_p75) - np.array(encoder_p25)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(k_values))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.bar(x - width/2, decoder_range, width, bottom=decoder_p25, \n",
    "            label='Decoder (25th-75th)', color='skyblue', alpha=0.7)\n",
    "    plt.bar(x + width/2, encoder_range, width, bottom=encoder_p25,\n",
    "            label='Encoder (25th-75th)', color='lightcoral', alpha=0.7)\n",
    "\n",
    "    for i in range(len(k_values)):\n",
    "        plt.plot([i - width/2 - width/4, i - width/2 + width/4], \n",
    "                 [decoder_p25[i], decoder_p25[i]], color='blue', linewidth=2)\n",
    "        plt.plot([i - width/2 - width/4, i - width/2 + width/4], \n",
    "                 [decoder_p75[i], decoder_p75[i]], color='blue', linewidth=2)\n",
    "        \n",
    "        plt.plot([i + width/2 - width/4, i + width/2 + width/4], \n",
    "                 [encoder_p25[i], encoder_p25[i]], color='red', linewidth=2)\n",
    "        plt.plot([i + width/2 - width/4, i + width/2 + width/4], \n",
    "                 [encoder_p75[i], encoder_p75[i]], color='red', linewidth=2)\n",
    "\n",
    "    plt.xlabel('Top-k Value')\n",
    "    plt.ylabel('Cosine Similarity')\n",
    "    if width_power == 14:\n",
    "        plt.title(f'25th-75th Percentile Ranges of Cosine Similarities (TopK, 16k Width)')\n",
    "    elif width_power == 16:\n",
    "        plt.title(f'25th-75th Percentile Ranges of Cosine Similarities (TopK, 65k Width)')\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid width power: {width_power}\")\n",
    "    plt.xticks(x, k_values)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(f'topk_cos_sim_analysis_width_{width_str}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # For width 2^14\n",
    "    analyze_cos_similarities(14)\n",
    "    \n",
    "    # For width 2^16\n",
    "    analyze_cos_similarities(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cos_similarities_relu(width_power):\n",
    "    \"\"\"\n",
    "    Analyze cosine similarities between before and after SAE weights for a given width.\n",
    "    \n",
    "    Args:\n",
    "        width_power (int): Power of 2 for width (e.g., 14 for 2^14 or 16 for 2^16)\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    from huggingface_hub import hf_hub_download\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    trainer_ids = list(range(6))\n",
    "    before_local_dir = \"before_relu_cos_sim_saes\"\n",
    "    after_local_dir = \"after_relu_cos_sim_saes_v2\"\n",
    "\n",
    "\n",
    "    width_str = f\"2pow{width_power}\"\n",
    "\n",
    "    before_repo_id = f\"canrager/saebench_gemma-2-2b_width-{width_str}_date-0107\"\n",
    "    after_repo_id = \"adamkarvonen/new_kl_finetunes\"\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for trainer_id in trainer_ids:\n",
    "        base_path = f\"gemma-2-2b_standard_new_width-{width_str}_date-0107/resid_post_layer_12/trainer_{trainer_id}/ae.pt\"\n",
    "        \n",
    "        path_to_before_params = hf_hub_download(\n",
    "            repo_id=before_repo_id,\n",
    "            filename=base_path,\n",
    "            force_download=False,\n",
    "            local_dir=before_local_dir,\n",
    "        )\n",
    "\n",
    "        path_to_after_params = hf_hub_download(\n",
    "            repo_id=after_repo_id,\n",
    "            filename=base_path,\n",
    "            force_download=False,\n",
    "            local_dir=after_local_dir,\n",
    "        )\n",
    "\n",
    "        before_params = torch.load(path_to_before_params)\n",
    "        after_params = torch.load(path_to_after_params)\n",
    "\n",
    "        # ... existing code for calculating decoder similarities ...\n",
    "        before_decoder = before_params['decoder.weight']\n",
    "        after_decoder = after_params['decoder.weight']\n",
    "        before_decoder_norm = before_decoder / before_decoder.norm(dim=0, keepdim=True)\n",
    "        after_decoder_norm = after_decoder / after_decoder.norm(dim=0, keepdim=True)\n",
    "        \n",
    "        decoder_cos_sims = torch.sum(before_decoder_norm * after_decoder_norm, dim=0)\n",
    "        \n",
    "        # Calculate decoder statistics\n",
    "        decoder_stats = {\n",
    "            'mean': decoder_cos_sims.mean().item(),\n",
    "            'median': decoder_cos_sims.median().item(),\n",
    "            'std': decoder_cos_sims.std().item(),\n",
    "            'min': decoder_cos_sims.min().item(),\n",
    "            'max': decoder_cos_sims.max().item(),\n",
    "            'p25': decoder_cos_sims.quantile(0.25).item(),\n",
    "            'p75': decoder_cos_sims.quantile(0.75).item(),\n",
    "        }\n",
    "        \n",
    "        # ... existing code for calculating encoder similarities ...\n",
    "        before_encoder = before_params['encoder.weight']\n",
    "        after_encoder = after_params['encoder.weight']\n",
    "\n",
    "        before_encoder_norm = before_encoder / before_encoder.norm(dim=1, keepdim=True)\n",
    "        after_encoder_norm = after_encoder / after_encoder.norm(dim=1, keepdim=True)\n",
    "        \n",
    "        encoder_cos_sims = torch.sum(before_encoder_norm * after_encoder_norm, dim=1)\n",
    "\n",
    "        assert (encoder_cos_sims.shape[0] == 16384) or (encoder_cos_sims.shape[0] == 65536)\n",
    "        assert (decoder_cos_sims.shape[0] == 16384) or (decoder_cos_sims.shape[0] == 65536)\n",
    "        \n",
    "        encoder_stats = {\n",
    "            'mean': encoder_cos_sims.mean().item(),\n",
    "            'median': encoder_cos_sims.median().item(),\n",
    "            'std': encoder_cos_sims.std().item(),\n",
    "            'min': encoder_cos_sims.min().item(),\n",
    "            'max': encoder_cos_sims.max().item(),\n",
    "            'p25': encoder_cos_sims.quantile(0.25).item(),\n",
    "            'p75': encoder_cos_sims.quantile(0.75).item(),\n",
    "        }\n",
    "        \n",
    "        result = {\n",
    "            'trainer_id': trainer_id,\n",
    "            'decoder': decoder_stats,\n",
    "            'encoder': encoder_stats,\n",
    "            'decoder_cos_sims': decoder_cos_sims.cpu().numpy(),\n",
    "            'encoder_cos_sims': encoder_cos_sims.cpu().numpy(),\n",
    "        }\n",
    "        all_results.append(result)\n",
    "        \n",
    "        print(f\"\\nTrainer {trainer_id}:\")\n",
    "        print(f\"Decoder statistics:\")\n",
    "        print(f\"  Mean: {decoder_stats['mean']:.4f}\")\n",
    "        print(f\"  Median: {decoder_stats['median']:.4f}\")\n",
    "        print(f\"  Std: {decoder_stats['std']:.4f}\")\n",
    "        print(f\"  Min/Max: {decoder_stats['min']:.4f}/{decoder_stats['max']:.4f}\")\n",
    "        print(f\"  25th/75th percentile: {decoder_stats['p25']:.4f}/{decoder_stats['p75']:.4f}\")\n",
    "        \n",
    "        print(f\"\\nEncoder statistics:\")\n",
    "        print(f\"  Mean: {encoder_stats['mean']:.4f}\")\n",
    "        print(f\"  Median: {encoder_stats['median']:.4f}\")\n",
    "        print(f\"  Std: {encoder_stats['std']:.4f}\")\n",
    "        print(f\"  Min/Max: {encoder_stats['min']:.4f}/{encoder_stats['max']:.4f}\")\n",
    "        print(f\"  25th/75th percentile: {encoder_stats['p25']:.4f}/{encoder_stats['p75']:.4f}\")\n",
    "\n",
    "    # Plot creation\n",
    "    k_values = [20, 40, 80, 160, 320, 640]\n",
    "    decoder_p25 = [result['decoder']['p25'] for result in all_results]\n",
    "    decoder_p75 = [result['decoder']['p75'] for result in all_results]\n",
    "    encoder_p25 = [result['encoder']['p25'] for result in all_results]\n",
    "    encoder_p75 = [result['encoder']['p75'] for result in all_results]\n",
    "\n",
    "    decoder_range = np.array(decoder_p75) - np.array(decoder_p25)\n",
    "    encoder_range = np.array(encoder_p75) - np.array(encoder_p25)\n",
    "\n",
    "    trainer_labels = ['Highest L0', \n",
    "                     '', \n",
    "                     '',\n",
    "                     '',\n",
    "                     '',\n",
    "                     'Lowest L0']\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(trainer_labels))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.bar(x - width/2, decoder_range, width, bottom=decoder_p25, \n",
    "            label='Decoder (25th-75th)', color='skyblue', alpha=0.7)\n",
    "    plt.bar(x + width/2, encoder_range, width, bottom=encoder_p25,\n",
    "            label='Encoder (25th-75th)', color='lightcoral', alpha=0.7)\n",
    "\n",
    "    for i in range(len(trainer_labels)):\n",
    "        plt.plot([i - width/2 - width/4, i - width/2 + width/4], \n",
    "                 [decoder_p25[i], decoder_p25[i]], color='blue', linewidth=2)\n",
    "        plt.plot([i - width/2 - width/4, i - width/2 + width/4], \n",
    "                 [decoder_p75[i], decoder_p75[i]], color='blue', linewidth=2)\n",
    "        \n",
    "        plt.plot([i + width/2 - width/4, i + width/2 + width/4], \n",
    "                 [encoder_p25[i], encoder_p25[i]], color='red', linewidth=2)\n",
    "        plt.plot([i + width/2 - width/4, i + width/2 + width/4], \n",
    "                 [encoder_p75[i], encoder_p75[i]], color='red', linewidth=2)\n",
    "\n",
    "    plt.xlabel('Trainers (Ordered by Decreasing L0 Sparsity)')\n",
    "    plt.ylabel('Cosine Similarity')\n",
    "    if width_power == 14:\n",
    "        plt.title(f'25th-75th Percentile Ranges of Cosine Similarities\\n(ReLU, 16k Width)')\n",
    "    elif width_power == 16:\n",
    "        plt.title(f'25th-75th Percentile Ranges of Cosine Similarities\\n(ReLU, 65k Width)')\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid width power: {width_power}\")\n",
    "    \n",
    "    plt.xticks(x, trainer_labels, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(f'relu_cos_sim_analysis_width_{width_str}.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For width 2^14\n",
    "    analyze_cos_similarities_relu(14)\n",
    "    \n",
    "    # For width 2^16\n",
    "    analyze_cos_similarities_relu(16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
